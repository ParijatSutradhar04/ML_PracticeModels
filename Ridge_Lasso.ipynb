{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba96d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bce39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 1 to 506\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     333 non-null    float64\n",
      " 1   zn       333 non-null    float64\n",
      " 2   indus    333 non-null    float64\n",
      " 3   chas     333 non-null    int64  \n",
      " 4   nox      333 non-null    float64\n",
      " 5   rm       333 non-null    float64\n",
      " 6   age      333 non-null    float64\n",
      " 7   dis      333 non-null    float64\n",
      " 8   rad      333 non-null    int64  \n",
      " 9   tax      333 non-null    int64  \n",
      " 10  ptratio  333 non-null    float64\n",
      " 11  black    333 non-null    float64\n",
      " 12  lstat    333 non-null    float64\n",
      " 13  medv     333 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 39.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "ID                                                                              \n",
       "1   0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "2   0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "4   0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5   0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "7   0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
       "\n",
       "     black  lstat  medv  \n",
       "ID                       \n",
       "1   396.90   4.98  24.0  \n",
       "2   396.90   9.14  21.6  \n",
       "4   394.63   2.94  33.4  \n",
       "5   396.90   5.33  36.2  \n",
       "7   395.60  12.43  22.9  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import training dataset\n",
    "train_df = pd.read_csv('train.csv', index_col='ID')\n",
    "\n",
    "#see the columns in our data\n",
    "train_df.info()\n",
    "\n",
    "# take a look at the head of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b7df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('medv', axis=1)\n",
    "y = train_df['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06550d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7268827869293253\n",
      "Test score: 0.7254687959254544\n",
      "RMSE: 4.587100299689447\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lr_model.score(X_test, y_test)))\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print('RMSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e350df",
   "metadata": {},
   "source": [
    "We need to create polynomial features by taking our individual features and raising them to a chosen power. Thankfully, scikit-learn has an implementation for this and we donâ€™t need to do it manually.\n",
    "\n",
    "Something else we would like to do is standardize our data. This scales our data down to a range between 0 and 1. This serves the purpose of letting us work with reasonable numbers when we raise to a power.\n",
    "\n",
    "Finally, because we need to carry out the same operations on our training, validation, and test sets, we will introduce a pipeline. This will let us pipe our process so the same steps get carried out repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db320646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9475767600691031\n",
      "Test score: 0.4676268497188807\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(pipeline.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15cfbb",
   "metadata": {},
   "source": [
    "Regularization or Ridge Regression\n",
    "\n",
    "To understand Ridge Regression, we need to remind ourselves of what happens during gradient descent, when our model coefficients are trained. During training, our initial weights are updated according to a gradient update rule using a learning rate and a gradient. Ridge regression adds a penalty to the update, and as a result shrinks the size of our weights. This is implemented in scikit-learn as a class called Ridge.\n",
    "\n",
    "We will create a new pipeline, this time using Ridge. We will specify our regularization strength by passing in a parameter, alpha. This can be really small, like 0.1, or as large as you would want it to be. The larger the value of alpha, the less variance your model will exhibit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57644d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9181086448043113\n",
      "Test Score: 0.8287450913722815\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=10, fit_intercept=True))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: {}'.format(ridge_pipe.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(ridge_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff5376",
   "metadata": {},
   "source": [
    "Regularization or Lasso Regression\n",
    "\n",
    "By creating a polynomial model, we created additional features. The question we need to ask ourselves is which of our features are relevant to our model, and which are not.\n",
    "\n",
    "l1 regularization tries to answer this question by driving the values of certain coefficients down to 0. This eliminates the least important features in our model. We will create a pipeline similar to the one above, but using Lasso. You can play around with the value of alpha, which can range from 0.1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf20c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.8483818643379695\n",
      "Test score: 0.8307977758339726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.3, fit_intercept=True))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lasso_pipe.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lasso_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade6fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
